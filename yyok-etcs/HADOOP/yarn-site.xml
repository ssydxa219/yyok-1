<?xml version="1.0"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>
    <!-- Site specific YARN configuration properties -->
    <property>
        <name>yarn.resourcemanager.cluster-id</name>
        <value>yyok_yarn</value>
    </property>
    <property>
        <name>yarn.resourcemanager.connect.retry-interval.ms</name>
        <value>2000</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.rm-ids</name>
        <value>rma,rmb</value>
    </property>
    <property>
        <name>ha.zookeeper.quorum</name>
        <value>dda:2181,ddb:2181,ddc:2181</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname.rma</name>
        <value>ddc</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname.rmb</name>
        <value>ddd</value>
    </property>
    <property>
        <name>yarn.resourcemanager.recovery.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.resourcemanager.zk-state-store.address</name>
        <value>dda:2181,ddb:2181,ddc:2181</value>
    </property>
    <!--org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore   ,ZKRMStateStore  -->
    <property>
        <name>yarn.resourcemanager.store.class</name>
        <value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>
    </property>
    <property>
        <name>yarn.resourcemanager.zk-address</name>
        <value>dda:2181,ddb:2181,ddc:2181</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.scheduler.connection.wait.interval-ms</name>
        <value>5000</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address.rma</name>
        <value>ddc:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address.rma</name>
        <value>ddc:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address.rma</name>
        <value>ddc:8088</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address.rma</name>
        <value>ddc:8031</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address.rma</name>
        <value>ddc:8033</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.admin.address.rma</name>
        <value>ddc:8034</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address.rmb</name>
        <value>ddd:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address.rmb</name>
        <value>ddd:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address.rmb</name>
        <value>ddd:8088</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address.rmb</name>
        <value>ddd:8031</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address.rmb</name>
        <value>ddd:8033</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.admin.address.rmb</name>
        <value>ddd:8034</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/ddhome/local/hadoop/yarn</value>
    </property>
    <property>
        <name>yarn.nodemanager.log-dirs</name>
        <value>/ddhome/local/hadoop/log</value>
    </property>
    <property>
        <name>mapreduce.shuffle.port</name>
        <value>23080</value>
    </property>
    <property>
        <name>yarn.nodemanager.log.retain-seconds</name>
        <value>10800</value>
    </property>
    <property>
        <name>yarn.resourcemanager.fs.state-store.uri</name>
        <value>/ddhome/local/hadoop/yarn/rmstore</value>
    </property>
    <property>
        <name>yarn.client.failover-proxy-provider</name>
        <value>org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider</value>
    </property>
    <property>
        <name>yarn.resourcemanager.ha.automatic-failover.zk-base-path</name>
        <value>/ddhome/local/hadoop/yarn-leader-election</value>
        <description>Optional setting. The default value is /yarn-leader-election</description>
    </property>
    <property>
        <description>Classpath for typical applications.</description>
        <name>yarn.application.classpath</name>
        <value>
            $HADOOP_CONF_DIR,
            $HADOOP_COMMON_HOME/share/hadoop/common/*,
            $HADOOP_COMMON_HOME/share/hadoop/common/lib/*,
            $HADOOP_HDFS_HOME/share/hadoop/hdfs/*,
            $HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,
            $YARN_HOME/share/hadoop/yarn/*,
            $YARN_HOME/share/hadoop/yarn/lib/*,
            $YARN_HOME/share/hadoop/mapreduce/*,
            $YARN_HOME/share/hadoop/mapreduce/lib/*
        </value>
    </property>
    <property>
        <name>yarn.resourcemanager.am.max-attempts</name>
        <value>13</value>
        <description>
            The maximum number of application master execution attempts.
        </description>
    </property>
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.log-aggregation.retain-check-interval-seconds</name>
        <value>10800</value>
    </property>
    <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>106800</value>
    </property>
    <!--它们表示单个容器可以申请的最小与最大内存。-->
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>1024</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>15000</value>
    </property>


    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>13</value>
    </property>

    <property>
        <name>yarn.scheduler.minimum-allocation-vcores</name>
        <value>2</value>
    </property>

    <property>
        <name>yarn.scheduler.maximum-allocation-vcores</name>
        <value>13</value>
    </property>

    <!--前者表示单个节点可用的最大内存，RM中的两个值都不应该超过该值。后者表示虚拟内存率，即占task所用内存的百分比，默认为2.1.-->
    <property>
        <description>Amount of physical memory, in MB, that can be allocated
            for containers.
        </description>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>15000</value>
    </property>
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
        <description>Whether virtual memory limits will be enforced for containers</description>
    </property>
    <property>
        <description>Ratio between virtual memory to physical memory when
            setting memory limits for containers. Container allocations are
            expressed in terms of physical memory, and virtual memory usage
            is allowed to exceed this allocation by this ratio.
        </description>
        <name>yarn.nodemanager.vmem-pmem-ratio</name>
        <value>2.1</value>
    </property>
    <property>
        <name>yarn.log.server.url</name>
        <value>http://ddc:19888/jobhistory/logs</value>
    </property>
    <property>
        <name>mapreduce.map.memory.mb</name>
        <value>15000</value>
    </property>

    <property>
        <name>mapreduce.reduce.memory.mb</name>
        <value>15000</value>
    </property>

    <property>
        <name>mapreduce.map.java.opts</name>
        <value>-Xmx15000m</value>
    </property>

    <property>
        <name>mapreduce.reduce.java.opts</name>
        <value>-Xmx15000m</value>
    </property>

    <property>
        <name>yarn.resourcemanager.scheduler.monitor.enable</name>
        <value>true</value>
    </property>

    <!--  指定我们的任务调度使用fairScheduler的调度方式
     <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
     -->
    <property>
        <name>yarn.resourcemanager.scheduler.class</name>
        <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
    </property>

    <!--  指定我们的任务调度的配置文件路径  -->
    <property>
        <name>yarn.scheduler.fair.allocation.file</name>
        <value>/ddhome/bin/hadoop/etc/hadoop/fair-scheduler.xml</value>
    </property>

    <!-- 是否启用资源抢占，如果启用，那么当该队列资源使用
    yarn.scheduler.fair.preemption.cluster-utilization-threshold 这么多比例的时候，就从其他空闲队列抢占资源
      -->
    <property>
        <name>yarn.scheduler.fair.preemption</name>
        <value>true</value>
    </property>
    <property>
        <name>yarn.scheduler.fair.preemption.cluster-utilization-threshold</name>
        <value>0.8f</value>
    </property>


    <!-- 默认提交到default队列  -->
    <property>
        <name>yarn.scheduler.fair.user-as-default-queue</name>
        <value>true</value>
        <description>default is True</description>
    </property>

    <!-- 如果提交一个任务没有到任何的队列，是否允许创建一个新的队列，设置false不允许  -->
    <property>
        <name>yarn.scheduler.fair.allow-undeclared-pools</name>
        <value>false</value>
        <description>default is True</description>
    </property>

    <property>
        <name>yarn.nodemanager.remote-app-log-dir</name>
        <value>ddhome/var/hadoop</value>
    </property>
    <property>
        <name>yarn.nodemanager.remote-app-log-dir-suffix</name>
        <value>logs</value>
    </property>
    <property>
        <name>yarn.nodemanager.delete.debug-delay-sec</name>
        <value>600</value>
    </property>


    <!--property>
          <name>yarn.nodemanager.localizer.cache.target-size-mb</name>
          <value>2048</value>
   </property-->
    <!--多租户配置，新增，用于队列的权限管理，和mapred-site.xml配置文件配合使用，例如不同租户不能随意kill任务，只能kill属于自己的队列任务，超级用户除外-->
    <property>
        <name>yarn.acl.enable</name>
        <value>true</value>
    </property>
    　　　　　　
    <property>
        <name>yarn.admin.acl</name>
        <value>hadp</value>
    </property>
</configuration>
